{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3495cf2-54ef-4974-8bbb-d4d2ed2eb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_facenet import FaceNet\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17364991-1e77-4bd3-bce0-b9233414701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognitionSystem:\n",
    "    def __init__(self, config):\n",
    "        # Initialize paths\n",
    "        self.BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "        self.DATA_DIR = os.path.join(self.BASE_DIR, 'data')\n",
    "        \n",
    "        # Initialize models\n",
    "        self.embedder = FaceNet()\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        \n",
    "        # Database setup\n",
    "        self.mongodb_uri = config.get('mongodb_uri')\n",
    "        self.client = MongoClient(self.mongodb_uri)\n",
    "        self.db = self.client.face_recognition\n",
    "        self.collection = self.db.embeddings\n",
    "        \n",
    "        # Recognition parameters\n",
    "        self.recognition_threshold = config.get('recognition_threshold')\n",
    "        \n",
    "        # Initialize attendance sheet\n",
    "        self.attendance = pd.DataFrame(columns=[\"Name\", \"Time\", \"Date\", \"Status\"])\n",
    "\n",
    "    def extract_face(self, image_path):\n",
    "        \"\"\"Extract and preprocess face from image path\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "            \n",
    "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        faces = self.detector(rgb_img, 1)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            face = faces[0]\n",
    "            x1, y1 = max(face.left(), 0), max(face.top(), 0)\n",
    "            x2, y2 = min(face.right(), rgb_img.shape[1]), min(face.bottom(), rgb_img.shape[0])\n",
    "            \n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                return None\n",
    "                \n",
    "            face_region = rgb_img[y1:y2, x1:x2]\n",
    "            return cv2.resize(face_region, (160, 160))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def store_embeddings(self):\n",
    "        total_images = 0\n",
    "        success_count = 0\n",
    "        failed_images = []\n",
    "        skipped_persons = 0\n",
    "    \n",
    "        person_dirs = [d for d in os.listdir(self.DATA_DIR) \n",
    "                      if os.path.isdir(os.path.join(self.DATA_DIR, d))]\n",
    "        \n",
    "        for person_name in person_dirs:\n",
    "            # Check if person already exists in database\n",
    "            if self.collection.count_documents({\"person_name\": person_name}) > 0:\n",
    "                print(f\"⏩ Skipping {person_name} - already exists in database\")\n",
    "                skipped_persons += 1\n",
    "                continue\n",
    "    \n",
    "            person_dir = os.path.join(self.DATA_DIR, person_name)\n",
    "            print(f\"\\nProcessing: {person_name}\")\n",
    "            \n",
    "            image_files = [f for f in os.listdir(person_dir) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            person_embeddings = []\n",
    "            for image_file in image_files:\n",
    "                total_images += 1\n",
    "                image_path = os.path.join(person_dir, image_file)\n",
    "                face = self.extract_face(image_path)\n",
    "                \n",
    "                if face is not None:\n",
    "                    try:\n",
    "                        face = face.astype('float32') / 255.0\n",
    "                        face = np.expand_dims(face, axis=0)\n",
    "                        \n",
    "                        embedding = self.embedder.model.predict(face, verbose=0)[0]\n",
    "                        embedding /= np.linalg.norm(embedding)\n",
    "                        person_embeddings.append(embedding.tolist())\n",
    "                        success_count += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        failed_images.append(image_path)\n",
    "                else:\n",
    "                    failed_images.append(image_path)\n",
    "            \n",
    "            # Insert all embeddings at once for new person\n",
    "            if person_embeddings:\n",
    "                self.collection.insert_one({\n",
    "                    \"person_name\": person_name,\n",
    "                    \"embeddings\": person_embeddings\n",
    "                })\n",
    "    \n",
    "        print(\"\\n✅ Processing Complete!\")\n",
    "        print(f\"Total Persons Processed: {len(person_dirs) - skipped_persons}\")\n",
    "        print(f\"Skipped Existing Persons: {skipped_persons}\")\n",
    "        print(f\"Total Images Processed: {total_images}\")\n",
    "        print(f\"Successful Embeddings: {success_count}\")\n",
    "        print(f\"Failed Images: {len(failed_images)}\")\n",
    "        \n",
    "    def recognize_faces(self):\n",
    "        \"\"\"Real-time face recognition from webcam\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(3, 640)  # Width\n",
    "        cap.set(4, 480)  # Height\n",
    "        \n",
    "        # Load known embeddings\n",
    "        known_faces = list(self.collection.find())\n",
    "        names = []\n",
    "        embeddings = []\n",
    "        \n",
    "        for face in known_faces:\n",
    "            person_name = face['person_name']\n",
    "            if 'embeddings' in face:\n",
    "                for embedding in face['embeddings']:\n",
    "                    names.append(person_name)\n",
    "                    embeddings.append(embedding)\n",
    "        \n",
    "        embeddings = np.array(embeddings)\n",
    "        \n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            faces = self.detector(rgb)\n",
    "            \n",
    "            for face in faces:\n",
    "                x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "                face_img = rgb[y1:y2, x1:x2]\n",
    "                \n",
    "                if face_img.size == 0:\n",
    "                    continue\n",
    "                \n",
    "                resized = cv2.resize(face_img, (160, 160))\n",
    "                embedding = self.embedder.embeddings([resized])[0]\n",
    "                embedding /= np.linalg.norm(embedding)\n",
    "                \n",
    "                similarities = np.dot(embeddings, embedding)\n",
    "                best_match_idx = np.argmax(similarities)\n",
    "                best_similarity = similarities[best_match_idx]\n",
    "                \n",
    "                # Recognition logic\n",
    "                if best_similarity > self.recognition_threshold:\n",
    "                    name = names[best_match_idx]\n",
    "                    status = \"Present\"\n",
    "                    color = (0, 255, 0)  # Green for known faces\n",
    "                else:\n",
    "                    name = \"Unknown\"\n",
    "                    status = \"Unknown\"\n",
    "                    color = (0, 0, 255)  # Red for unknown faces\n",
    "                \n",
    "                # Update attendance only once per session\n",
    "                if name not in self.attendance.Name.values:\n",
    "                    now = datetime.now()\n",
    "                    self.attendance.loc[len(self.attendance)] = [\n",
    "                        name,\n",
    "                        now.strftime(\"%H:%M:%S\"),\n",
    "                        now.strftime(\"%Y-%m-%d\"),\n",
    "                        status\n",
    "                    ]\n",
    "                \n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, name, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "            \n",
    "            cv2.imshow('Face Recognition', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "    def mark_absentees(self):\n",
    "        \"\"\"Generate attendance report with absentees marked in a single consolidated file\"\"\"\n",
    "        registered = self.collection.distinct(\"person_name\")\n",
    "        today = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Use in-memory attendance data instead of reading from Excel\n",
    "        present = self.attendance[self.attendance[\"Date\"] == today][\"Name\"].unique().tolist()\n",
    "        \n",
    "        # Generate full attendance record for today\n",
    "        full_record = []\n",
    "        for person in registered:\n",
    "            status = \"Present\" if person in present else \"Absent\"\n",
    "            full_record.append({\n",
    "                \"Name\": person,\n",
    "                \"Date\": today,\n",
    "                \"Time\": datetime.now().strftime(\"%H:%M:%S\"),\n",
    "                \"Status\": status\n",
    "            })\n",
    "        \n",
    "        # Create DataFrame for today's records\n",
    "        df_today = pd.DataFrame(sorted(full_record, key=lambda x: x[\"Name\"]))\n",
    "        \n",
    "        # Define consolidated filename\n",
    "        consolidated_file = \"../attendance_data/attendance_records.xlsx\"\n",
    "        \n",
    "        # Append to existing file or create new\n",
    "        if os.path.exists(consolidated_file):\n",
    "            existing_df = pd.read_excel(consolidated_file)\n",
    "            updated_df = pd.concat([existing_df, df_today], ignore_index=True)\n",
    "        else:\n",
    "            updated_df = df_today\n",
    "        \n",
    "        # Save consolidated data\n",
    "        updated_df = updated_df.drop_duplicates(subset=[\"Name\", \"Date\"], keep=\"last\")\n",
    "        updated_df.to_excel(consolidated_file, index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3083301-ad5b-441f-acb3-263f46711583",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"mongodb_uri\": \"mongodb://localhost:27017/face-recognition\",\n",
    "    \"recognition_threshold\": 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d25659-3c85-49ca-a9b7-8e3801e1a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏩ Skipping 2_Dipesh_Bajgain - already exists in database\n",
      "⏩ Skipping 4_diense - already exists in database\n",
      "⏩ Skipping 8_dinesh - already exists in database\n",
      "⏩ Skipping 4_dinesh - already exists in database\n",
      "⏩ Skipping 9_Milan_Bajgain - already exists in database\n",
      "⏩ Skipping 4_Dinesh_Bajgain - already exists in database\n",
      "⏩ Skipping 8_Harendra_sir - already exists in database\n",
      "⏩ Skipping 3_Ayudh_Pantha - already exists in database\n",
      "⏩ Skipping 6_Dpt_Prjuli - already exists in database\n",
      "⏩ Skipping 18_SRK - already exists in database\n",
      "⏩ Skipping 10_Bibek_Adhikari - already exists in database\n",
      "\n",
      "✅ Processing Complete!\n",
      "Total Persons Processed: 0\n",
      "Skipped Existing Persons: 11\n",
      "Total Images Processed: 0\n",
      "Successful Embeddings: 0\n",
      "Failed Images: 0\n"
     ]
    }
   ],
   "source": [
    "frs = FaceRecognitionSystem(config)\n",
    "\n",
    "# Store embeddings from images\n",
    "frs.store_embeddings()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be7e9bc9-f2f1-4e8f-bbfe-8477a4347292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    }
   ],
   "source": [
    "# Run real-time recognition\n",
    "frs.recognize_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4703eb-ca75-4f3d-ad2f-95b9206cb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate attendance report\n",
    "frs.mark_absentees()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
